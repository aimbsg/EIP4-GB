{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2 (9th CNN) - GB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbsg/EIP4-GB/blob/master/Session_2_(9th_CNN)_GB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "outputId": "f3c733fb-e9f0-418e-bd21-6d067df0cd4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "outputId": "c7f63a1d-3460-4224-f444-56fab27ee0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "a4286c53-ef20-4e9d-b00f-bef40ec4ef97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7d0d8936a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2IEg/h8CIWRCsmbzCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "ad730c6d-4e32-46fb-b0db-48ca3242dac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "5d57017c-394e-4073-b0ba-6ba23f1798c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,060\n",
            "Trainable params: 13,848\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "7d19aba2-a5ed-4f76-ee26-6a25e9faf5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.4245 - acc: 0.9001 - val_loss: 0.0947 - val_acc: 0.9840\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.1748 - acc: 0.9536 - val_loss: 0.0577 - val_acc: 0.9868\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.1321 - acc: 0.9664 - val_loss: 0.0574 - val_acc: 0.9863\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.1129 - acc: 0.9716 - val_loss: 0.0491 - val_acc: 0.9879\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0976 - acc: 0.9755 - val_loss: 0.0324 - val_acc: 0.9917\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0890 - acc: 0.9771 - val_loss: 0.0316 - val_acc: 0.9926\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0795 - acc: 0.9788 - val_loss: 0.0279 - val_acc: 0.9929\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0732 - acc: 0.9806 - val_loss: 0.0256 - val_acc: 0.9932\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0700 - acc: 0.9806 - val_loss: 0.0266 - val_acc: 0.9927\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0656 - acc: 0.9818 - val_loss: 0.0264 - val_acc: 0.9929\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0621 - acc: 0.9814 - val_loss: 0.0247 - val_acc: 0.9927\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0562 - acc: 0.9834 - val_loss: 0.0243 - val_acc: 0.9928\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0563 - acc: 0.9829 - val_loss: 0.0233 - val_acc: 0.9936\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0509 - acc: 0.9844 - val_loss: 0.0223 - val_acc: 0.9939\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0504 - acc: 0.9834 - val_loss: 0.0220 - val_acc: 0.9934\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0496 - acc: 0.9837 - val_loss: 0.0230 - val_acc: 0.9939\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0472 - acc: 0.9841 - val_loss: 0.0215 - val_acc: 0.9942\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0464 - acc: 0.9842 - val_loss: 0.0214 - val_acc: 0.9942\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0456 - acc: 0.9847 - val_loss: 0.0224 - val_acc: 0.9937\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0431 - acc: 0.9852 - val_loss: 0.0213 - val_acc: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c9a85c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "e126d032-3ef8-4d25-9105-d7426587d403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.021295674181287177, 0.994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}